{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os\n",
    "import threading\n",
    "import psutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_df(df):\n",
    "    df.drop(df[df['Operating_Area']=='9999999999'].index,inplace=True)\n",
    "    df = df.dropna(axis=0)\n",
    "    df.axis=0\n",
    "\n",
    "    #지운 행렬이 존재하므로 인덱스 행 재정렬\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    #정상적인 좌표값 계산을 위해 현재 .(점) 없이 기재되어있는 좌표 숫자를 정상적으로 인식할 수 있게 .을 붙여줍니다.\n",
    "    df['LAT'] = df['LAT'].astype(float).div(1000000).round(6)\n",
    "    df['LNG'] = df['LNG'].astype(float).div(1000000).round(6)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "\n",
    "def get_orderby_car_number(df, route, threshold=0.00030):\n",
    "    \"\"\"\n",
    "    벡터화 방식으로 각 버스 위치가 인접한 정류장을 찾는 함수\n",
    "    df     : 버스 데이터프레임 (LNG, LAT 열 포함)\n",
    "    route  : 정류장 정보가 담긴 데이터프레임 (LNG, LAT 열 포함)\n",
    "    threshold : 인접 판단 임계값 (0.00030 이내면 도착으로 간주)\n",
    "    \"\"\"\n",
    "\n",
    "    # 정류장과 버스 위치 좌표 추출\n",
    "    bus_stops = route[['LNG', 'LAT']].values  # shape = (M, 2)\n",
    "    coords = df[['LNG', 'LAT']].values        # shape = (N, 2)\n",
    "\n",
    "    # (N×M) 크기의 거리 행렬 생성\n",
    "    dist_mat = distance_matrix(coords, bus_stops)  # scipy.spatial.distance_matrix\n",
    "\n",
    "    # 각 버스 위치(행)에 대해 가장 가까운 정류장까지의 거리 계산\n",
    "    min_dist_array = dist_mat.min(axis=1)\n",
    "\n",
    "    # 임계값 이하인 경우를 bus_stop=True로 표시\n",
    "    df['bus_stop'] = min_dist_array <= threshold\n",
    "\n",
    "    # 버스정류장에 도착한 행만 필터링\n",
    "    trueBusStop = df[df['bus_stop']].reset_index(drop=True)\n",
    "\n",
    "    # 필요한 열만 반환 (원하시는 열 구성에 맞춰 조정)\n",
    "    return trueBusStop[['LNG', 'LAT', 'Information_Occurrence', 'Car_RegistrationNumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_size(file_path, memory_limit):\n",
    "    \"\"\"\n",
    "    파일에서 샘플 데이터를 읽어 한 행당 메모리 크기를 계산하고\n",
    "    주어진 메모리 제한에 맞는 청크 크기를 반환합니다.\n",
    "    \"\"\"\n",
    "    # 샘플 데이터 읽기\n",
    "    sample = pd.read_csv(file_path, sep='|', header=None, nrows=100, encoding='utf-8')\n",
    "    sample_memory = sample.memory_usage(deep=True).sum()  # 샘플 데이터 메모리 사용량\n",
    "    row_memory = sample_memory / len(sample)  # 한 행당 평균 메모리 크기\n",
    "    chunk_size = int(memory_limit / row_memory)  # 청크 크기 계산\n",
    "    return chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_chunks(bus_path, busro, chunk_size):\n",
    "    columns = ['Trip_Key', 'Recorder_Model', 'Car_RentalNumber', 'Car_Type', 'Car_RegistrationNumber', \n",
    "               'Carrier_RegistrationNumber', 'Driver_Code', 'Day_Drive', 'Total_Drive', 'Car_Speed', \n",
    "               'Engine_Rotation', 'Break_Signal', 'LNG', 'LAT', 'GIS_Azimuth', 'Acceleration_Vx', \n",
    "               'Acceleration_Vy', 'Status_Code', 'Operating_Area', 'Information_Occurrence']\n",
    "    result_columns = ['LNG', 'LAT', 'Information_Occurrence']\n",
    "\n",
    "    result = pd.DataFrame(columns=result_columns)\n",
    "\n",
    "    # 청크 단위로 데이터 읽기\n",
    "    chunk_num = 1\n",
    "    for chunk in pd.read_csv(bus_path, sep='|', header=None, names=columns, chunksize=chunk_size, encoding='utf-8'):\n",
    "        print(f\"Processing chunk {chunk_num} in {os.path.basename(bus_path)}\")\n",
    "        chunk = set_df(chunk)  # 사용자 정의 함수로 데이터 전처리\n",
    "        processed_chunk = get_orderby_car_number(chunk, busro)  # 사용자 정의 함수로 데이터 처리\n",
    "        result = pd.concat([result, processed_chunk], ignore_index=True)\n",
    "        chunk_num += 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, busro, memory_limit):\n",
    "    \"\"\"\n",
    "    파일 처리 함수: 주어진 메모리 제한에 맞춰 동적으로 청크 크기를 계산하여 처리.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {file_path} in Thread: {threading.current_thread().name}\")\n",
    "    chunk_size = calculate_chunk_size(file_path, memory_limit)\n",
    "    print(f\"Calculated chunk size: {chunk_size} rows\")\n",
    "    result = run_with_chunks(file_path, busro, chunk_size)\n",
    "\n",
    "    # 처리 결과 저장\n",
    "    output_path = file_path + '_processed.csv'\n",
    "    print(f\"Saving file to: {output_path}\")\n",
    "    result.to_csv(output_path, index=False, encoding=\"cp949\")\n",
    "    print(f\"File saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9 (process_file):\n",
      "Traceback (most recent call last):\n",
      "  File \"parsers.pyx\", line 1120, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "Exception in thread Thread-10 (process_file):\n",
      "Traceback (most recent call last):\n",
      "  File \"parsers.pyx\", line 1120, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "Exception in thread Thread-11 (process_file):\n",
      "Traceback (most recent call last):\n",
      "  File \"parsers.pyx\", line 1120, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "Exception in thread Thread-12 (process_file):\n",
      "Traceback (most recent call last):\n",
      "  File \"parsers.pyx\", line 1120, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 35: invalid continuation byte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 35: invalid continuation byte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 36: invalid continuation byte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 36: invalid continuation byte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\831151799.py\", line 6, in process_file\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\831151799.py\", line 6, in process_file\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\831151799.py\", line 6, in process_file\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\831151799.py\", line 6, in process_file\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\4142072366.py\", line 7, in calculate_chunk_size\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\4142072366.py\", line 7, in calculate_chunk_size\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\4142072366.py\", line 7, in calculate_chunk_size\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13492\\4142072366.py\", line 7, in calculate_chunk_size\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 626, in _read\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 626, in _read\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 626, in _read\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1923, in read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1923, in read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1923, in read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 850, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 850, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 850, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 850, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 921, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 921, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 921, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 921, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 1066, in pandas._libs.parsers.TextReader._convert_column_data\n",
      "  File \"parsers.pyx\", line 1066, in pandas._libs.parsers.TextReader._convert_column_data\n",
      "  File \"parsers.pyx\", line 1066, in pandas._libs.parsers.TextReader._convert_column_data\n",
      "  File \"parsers.pyx\", line 1066, in pandas._libs.parsers.TextReader._convert_column_data\n",
      "  File \"parsers.pyx\", line 1127, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "  File \"parsers.pyx\", line 1127, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "  File \"parsers.pyx\", line 1127, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "  File \"parsers.pyx\", line 1127, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1272, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1285, in pandas._libs.parsers.TextReader._string_convert\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "  File \"parsers.pyx\", line 1535, in pandas._libs.parsers._string_box_utf8\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 35: invalid continuation byte\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 36: invalid continuation byte\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 36: invalid continuation byte\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 35: invalid continuation byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./data\\DTG-r-00000 in Thread: Thread-5 (process_file)\n",
      "Processing file: ./data\\DTG-r-00001 in Thread: Thread-6 (process_file)\n",
      "Processing file: ./data\\DTG-r-00002 in Thread: Thread-7 (process_file)\n",
      "Processing file: ./data\\DTG-r-00003 in Thread: Thread-8 (process_file)\n",
      "Processing file: ./data\\data\\DTG-r-00000_processed.csv in Thread: Thread-9 (process_file)\n",
      "Processing file: ./data\\data\\DTG-r-00001_processed.csv in Thread: Thread-10 (process_file)\n",
      "Processing file: ./data\\data\\DTG-r-00002_processed.csv in Thread: Thread-11 (process_file)\n",
      "Processing file: ./data\\data\\DTG-r-00003_processed.csv in Thread: Thread-12 (process_file)\n",
      "Calculated chunk size: 2697149 rows\n",
      "Calculated chunk size: 2697149 rows\n",
      "Calculated chunk size: 2697149 rows\n",
      "Calculated chunk size: 2697149 rows\n",
      "Processing chunk 1 in DTG-r-00002Processing chunk 1 in DTG-r-00000\n",
      "\n",
      "Processing chunk 1 in DTG-r-00003\n",
      "Processing chunk 1 in DTG-r-00001\n",
      "Processing chunk 2 in DTG-r-00002\n",
      "Processing chunk 2 in DTG-r-00003\n",
      "Processing chunk 2 in DTG-r-00000Processing chunk 2 in DTG-r-00001\n",
      "\n",
      "Processing chunk 3 in DTG-r-00002\n",
      "Processing chunk 3 in DTG-r-00003\n",
      "Processing chunk 3 in DTG-r-00000\n",
      "Processing chunk 3 in DTG-r-00001\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 버스 정보 데이터 파일 읽기\n",
    "    busro = pd.read_csv(\"./bus_route_specific_13.csv\", encoding='cp949')\n",
    "\n",
    "    # 루트 디렉토리 정의\n",
    "    root = \"./data\"\n",
    "    files = [os.path.join(path, name) for path, _, files in os.walk(root) for name in files]\n",
    "\n",
    "    # 사용 가능한 메모리 계산\n",
    "    total_memory = psutil.virtual_memory().available\n",
    "    thread_memory_limit = total_memory * 0.05  # 각 스레드에 20% 메모리 할당\n",
    "\n",
    "    # 쓰레드 리스트 생성\n",
    "    threads = []\n",
    "    for file_path in files:\n",
    "        thread = threading.Thread(target=process_file, args=(file_path, busro, thread_memory_limit))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # 모든 쓰레드가 완료될 때까지 대기\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"모든 파일 처리 완료\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
